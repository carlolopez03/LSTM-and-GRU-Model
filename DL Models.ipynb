{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db075fd7-28c0-4542-a736-89dd1fa67a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers, optimizers, regularizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "%load_ext autoreload \n",
    "%autoreload 2\n",
    "\n",
    "import custom_functions as fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a62cb32-9d9b-4522-b3c7-578fe5f26fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: custom_functions in c:\\users\\carlo\\anaconda3\\envs\\dojo-env\\lib\\site-packages (0.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install custom_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad92371c-7934-49fc-a95c-bd20b9b43556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id26305</th>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id17569</th>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id11008</th>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id27763</th>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "      <td>MWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id12958</th>\n",
       "      <td>Finding nothing else, not even gold, the Super...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text author\n",
       "id                                                               \n",
       "id26305  This process, however, afforded me no means of...    EAP\n",
       "id17569  It never once occurred to me that the fumbling...    HPL\n",
       "id11008  In his left hand was a gold snuff box, from wh...    EAP\n",
       "id27763  How lovely is spring As we looked from Windsor...    MWS\n",
       "id12958  Finding nothing else, not even gold, the Super...    HPL"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading Data\n",
    "df = pd.read_csv(\"Data/spooky.csv\", index_col = 'id')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9498dff-7eac-4449-a28b-75f56a680a20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id26305</th>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id17569</th>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id11008</th>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id27763</th>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "      <td>MWS</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id12958</th>\n",
       "      <td>Finding nothing else, not even gold, the Super...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text author  length\n",
       "id                                                                       \n",
       "id26305  This process, however, afforded me no means of...    EAP      41\n",
       "id17569  It never once occurred to me that the fumbling...    HPL      14\n",
       "id11008  In his left hand was a gold snuff box, from wh...    EAP      36\n",
       "id27763  How lovely is spring As we looked from Windsor...    MWS      34\n",
       "id12958  Finding nothing else, not even gold, the Super...    HPL      27"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Making length column for text\n",
    "df['length'] =df['text'].map( lambda x: len(x.split(\" \")))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c428f3ae-58c0-44dd-aefe-e40020c77bde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    19579.000000\n",
       "mean        26.730477\n",
       "std         19.048353\n",
       "min          2.000000\n",
       "25%         15.000000\n",
       "50%         23.000000\n",
       "75%         34.000000\n",
       "max        861.000000\n",
       "Name: length, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['length'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46834f51-20d4-4431-a858-011f79ca2211",
   "metadata": {},
   "source": [
    "- The range of sequence length is from 2 to 861.\n",
    "- The average sequence length is around 26 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "843644ae-6429-45f0-b5d1-74599be85309",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EAP    0.403494\n",
       "MWS    0.308698\n",
       "HPL    0.287808\n",
       "Name: author, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['author'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "349e4fc4-bae3-4c13-9bd7-3f8b3ff1c126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EAP    5635\n",
       "HPL    5635\n",
       "MWS    5635\n",
       "Name: author, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RUS to match minority group\n",
    "sampler = RandomUnderSampler(random_state=42)\n",
    "df,  _ = sampler.fit_resample(df, df['author'])\n",
    "df['author'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d97f370b-9084-4621-a49e-cd5a12ee695a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "id22483    0\n",
       "id18809    0\n",
       "id16322    0\n",
       "id13423    0\n",
       "id09553    0\n",
       "          ..\n",
       "id22356    2\n",
       "id11504    2\n",
       "id00149    2\n",
       "id16796    2\n",
       "id23776    2\n",
       "Name: author, Length: 16905, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Crating map for targets\n",
    "target_map = {'EAP':0,\n",
    "             'HPL':1,\n",
    "             'MWS':2}\n",
    "y = df['author'].map(target_map)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c6bdd5e-c81a-4ed6-8760-f23f3791cd9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['He then asked me, suddenly, if I had observed any thing peculiar at the scene of the atrocity.',\n",
       "       'Through the exertions of Beauvais, the matter was industriously hushed up, as far as possible; and several days had elapsed before any public emotion resulted.',\n",
       "       'The cold was intense, and obliged me to wrap up closely in an overcoat.',\n",
       "       ...,\n",
       "       'What I ask of you is reasonable and moderate; I demand a creature of another sex, but as hideous as myself; the gratification is small, but it is all that I can receive, and it shall content me.',\n",
       "       'The birth of her daughter, embryo copy of her Raymond, filled up the measure of her content, and produced a sacred and indissoluble tie between them.',\n",
       "       \"I heard my sister's sobs, and thought, happy are women who can weep, and in a passionate caress disburthen the oppression of their feelings; shame and habitual restraint hold back a man.\"],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X and y\n",
    "X = df['text'].values\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39bc53c3-1654-4686-8166-f132972a6394",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = y.unique()\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ab6456e-7cb7-4252-b3ec-b960ee44b652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to Dataset Object\n",
    "ds = tf.data.Dataset.from_tensor_slices((X, y))\n",
    "\n",
    "# Shuffle dataset\n",
    "ds = ds.shuffle(buffer_size=len(ds),reshuffle_each_iteration=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ca0469c-5dba-4758-b509-5c491f844bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    - train:\t11833 samples \t(370 batches)\n",
      "    - val:  \t3381 samples \t(106 batches)\n",
      "    - test: \t1691 samples \t(53 batches)\n"
     ]
    }
   ],
   "source": [
    "# Set the ratio of the train, validation, test split\n",
    "split_train = .7\n",
    "split_val =  .2\n",
    "split_test =  1 -( split_train + split_val )\n",
    "\n",
    "# Calculate the number of samples for training and validation data \n",
    "n_train_samples =  int(len(ds) * split_train)\n",
    "n_val_samples = int(len(ds) * split_val)\n",
    "n_test_samples = len(ds) -(n_train_samples + n_val_samples)\n",
    "\n",
    "# Set the batch size\n",
    "BATCH_SIZE =32\n",
    "\n",
    "\n",
    "import math\n",
    "# math.ceil will round up\n",
    "# How many batches? \n",
    "n_train_batches = math.ceil(n_train_samples/BATCH_SIZE)\n",
    "n_val_batches = math.ceil(n_val_samples/BATCH_SIZE)\n",
    "n_test_batches = math.ceil(n_test_samples/BATCH_SIZE)\n",
    "\n",
    "print(f\"    - train:\\t{n_train_samples} samples \\t({n_train_batches} batches)\")\n",
    "print(f\"    - val:  \\t{n_val_samples} samples \\t({n_val_batches} batches)\")\n",
    "print(f\"    - test: \\t{n_test_samples} samples \\t({n_test_batches} batches)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4624175-d676-4fbb-be77-40c8d759175f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use take and skip to define each set\n",
    "train_ds = ds.take(n_train_samples).batch(batch_size=BATCH_SIZE)\n",
    "\n",
    "# Skip over the training batches and take the validation batches\n",
    "val_ds = ds.skip(n_train_samples).take(n_val_samples).batch(batch_size=BATCH_SIZE)\n",
    "\n",
    "# Skipver the train and validation batches, the remaining are the test batches\n",
    "test_ds = ds.skip(n_train_samples + n_val_samples).batch(batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d56d8ce-a8ff-429b-8b70-39e7608c5e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " There are 370 training batches.\n",
      " There are 106 validation batches.\n",
      " There are 53 testing batches.\n"
     ]
    }
   ],
   "source": [
    "# Confirm the number of batches in each\n",
    "print (f' There are {len(train_ds)} training batches.')\n",
    "print (f' There are {len(val_ds)} validation batches.')\n",
    "print (f' There are {len(test_ds)} testing batches.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8482f787-27db-40b9-87e9-2e193588241b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQUENCE_LENGTH = 100\n",
    "# Create text Vectorization layer\n",
    "sequence_vectorizer = tf.keras.layers.TextVectorization(standardize=\"lower_and_strip_punctuation\",\n",
    "                                                        output_mode=\"int\",\n",
    "                                                        output_sequence_length=SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b83d6b6-0ac2-4341-91b0-0ee07f360de9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32,), dtype=string, numpy=\n",
       "array([b'Apparently it was a point somewhere between Hydra and Argo Navis, and he knew that he had been urged toward it ever since he had awaked soon after dawn.',\n",
       "       b'For many months after that Kuranes sought the marvellous city of Celepha\\xc3\\xafs and its sky bound galleys in vain; and though his dreams carried him to many gorgeous and unheard of places, no one whom he met could tell him how to find Ooth Nargai, beyond the Tanarian Hills.',\n",
       "       b'He often left Perdita, to wander in the grounds alone; or in a light shallop he floated idly on the pure waters, musing deeply.',\n",
       "       b'You seek for knowledge and wisdom, as I once did; and I ardently hope that the gratification of your wishes may not be a serpent to sting you, as mine has been.',\n",
       "       b'And through this revolting graveyard of the universe the muffled, maddening beating of drums, and thin, monotonous whine of blasphemous flutes from inconceivable, unlighted chambers beyond Time; the detestable pounding and piping whereunto dance slowly, awkwardly, and absurdly the gigantic, tenebrous ultimate gods the blind, voiceless, mindless gargoyles whose soul is Nyarlathotep.',\n",
       "       b\"Through my father's exertions a part of the inheritance of Elizabeth had been restored to her by the Austrian government.\",\n",
       "       b'Now it is agreed by all the distant relatives of Randolph Carter that something occurred to heighten his imagination in his tenth year.',\n",
       "       b'All attempts at logical inquiry resulted, indeed, in leaving me more sceptical than before.',\n",
       "       b'And was I really as mad as the whole world would believe me to be if I disclosed the object of my suspicions?',\n",
       "       b\"Raymond's answer was brief.\",\n",
       "       b'No man can tell there is no refuge on earth, it comes on us like a thousand packs of wolves we must all fly where shall you go?',\n",
       "       b'He had taken somewhat after his unknown father.',\n",
       "       b'And thus, too, it happened, perhaps, that before the last echoes of the last chime had utterly sunk into silence, there were many individuals in the crowd who had found leisure to become aware of the presence of a masked figure which had arrested the attention of no single individual before.',\n",
       "       b'The great war was then at its very beginning, and the ocean forces of the Hun had not completely sunk to their later degradation; so that our vessel was made a legitimate prize, whilst we of her crew were treated with all the fairness and consideration due us as naval prisoners.',\n",
       "       b'On the morning of September th Professor Rice and Dr. Morgan insisted on seeing him for a while, and departed trembling and ashen grey.',\n",
       "       b'There were two armlets, a tiara, and a kind of pectoral; the latter having in high relief certain figures of almost unbearable extravagance.',\n",
       "       b'They were both then lying on the sacking of the bedstead in the chamber where Mademoiselle L. was found.',\n",
       "       b'She seemed to consider that through me she had lost Raymond; I was the evil influence of her life; I was even accused of encreasing and confirming the mad and base apostacy of Adrian from all views of advancement and grandeur; and now this miserable mountaineer was to steal her daughter.',\n",
       "       b\"God, that hand The window The window When the last days were upon me, and the ugly trifles of existence began to drive me to madness like the small drops of water that torturers let fall ceaselessly upon one spot of their victim's body, I loved the irradiate refuge of sleep.\",\n",
       "       b'We are ready to expose our breasts, exposed ten thousand times before, to the balls and scymetars of the infidels, and to fall gloriously for Greece.',\n",
       "       b'But it is needless to say that I stood upon the principle of the thing.',\n",
       "       b'This was a state of things not to be endured.',\n",
       "       b'Ignorant and dirty, he was at home amongst the other brown skinned Mexicans; having come so I was afterward told from the very lowest sort of surroundings.',\n",
       "       b\"When he and I obtained our degrees at the medical school of Miskatonic University, and sought to relieve our poverty by setting up as general practitioners, we took great care not to say that we chose our house because it was fairly well isolated, and as near as possible to the potter's field.\",\n",
       "       b'\"There is nothing at all like it,\" he would say; \"we are a wonderful people, and live in a wonderful age.',\n",
       "       b'The style that was the thing.',\n",
       "       b'His voice seemed suffocated, and my first impulses, which had suggested to me the duty of obeying the dying request of my friend in destroying his enemy, were now suspended by a mixture of curiosity and compassion.',\n",
       "       b'Frederick was, at that time, in his fifteenth year.',\n",
       "       b'This spot had for me peculiar charms.',\n",
       "       b'Was it my own excited imagination or the misty influence of the atmosphere or the uncertain twilight of the chamber or the gray draperies which fell around her figure that caused in it so vacillating and indistinct an outline?',\n",
       "       b'I had one female servant who spent the greater part of the day at a village two miles off.',\n",
       "       b'On March d, the manuscript continued, Wilcox failed to appear; and inquiries at his quarters revealed that he had been stricken with an obscure sort of fever and taken to the home of his family in Waterman Street.'],\n",
       "      dtype=object)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get just the text from ds_train\n",
    "ds_texts = train_ds.map(lambda x, y: x)\n",
    "\n",
    "# Preview the text\n",
    "ds_texts.take(1).get_single_element()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c7f66bb4-affc-473b-ba92-e5e451fda909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20884"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train (adapt on training text data))\n",
    "sequence_vectorizer.adapt(ds_texts)\n",
    "sequence_vectorizer.vocabulary_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "626a564d-9759-4300-96a1-367121ffe607",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm_model(text_vectorization_layer):\n",
    "    VOCAB_SIZE = sequence_vectorizer.vocabulary_size()\n",
    "    SEQUENCE_LENGTH = sequence_vectorizer.get_config()['output_sequence_length']\n",
    "    EMBED_DIM = 150\n",
    "    \n",
    "    # Define sequential model with pre-trained vectorization layer and *new* embedding layer\n",
    "    lstm_model = Sequential([\n",
    "        text_vectorization_layer,\n",
    "        layers.Embedding(input_dim=VOCAB_SIZE,\n",
    "                                  output_dim=EMBED_DIM, \n",
    "                                  input_length=SEQUENCE_LENGTH)\n",
    "        ])\n",
    "        \n",
    "    # Add *new* LSTM layer\n",
    "    lstm_model.add(layers.LSTM(128))\n",
    "    # Add output layer\n",
    "    lstm_model.add(layers.Dense(len(classes), activation='softmax'))\n",
    " \n",
    "    # Compile the model\n",
    "    lstm_model.compile(optimizer=optimizers.legacy.Adam(learning_rate = .01), \n",
    "                  loss='sparse_categorical_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    lstm_model.summary()\n",
    "    return lstm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aab69523-041e-413d-9855-297bee0ca614",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_callbacks(patience=3, monitor='val_accuracy'):\n",
    "    early_stop = tf.keras.callbacks.EarlyStopping(patience=patience, monitor=monitor)\n",
    "    return [early_stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d53ad177-e2a8-42c7-a9c3-b067bdcac12c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " text_vectorization (TextVec  (None, 100)              0         \n",
      " torization)                                                     \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 100, 150)          3132600   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 128)               142848    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,275,835\n",
      "Trainable params: 3,275,835\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "370/370 [==============================] - 25s 65ms/step - loss: 1.1087 - accuracy: 0.3295 - val_loss: 1.1017 - val_accuracy: 0.3336\n",
      "Epoch 2/30\n",
      "370/370 [==============================] - 24s 64ms/step - loss: 1.0996 - accuracy: 0.3304 - val_loss: 1.0981 - val_accuracy: 0.3351\n",
      "Epoch 3/30\n",
      "370/370 [==============================] - 24s 64ms/step - loss: 1.0986 - accuracy: 0.3340 - val_loss: 1.0977 - val_accuracy: 0.3348\n",
      "Epoch 4/30\n",
      "370/370 [==============================] - 24s 64ms/step - loss: 1.0976 - accuracy: 0.3330 - val_loss: 1.0982 - val_accuracy: 0.3342\n",
      "Epoch 5/30\n",
      "370/370 [==============================] - 24s 65ms/step - loss: 1.0931 - accuracy: 0.3505 - val_loss: 1.0648 - val_accuracy: 0.4102\n",
      "Epoch 6/30\n",
      "370/370 [==============================] - 24s 65ms/step - loss: 0.9731 - accuracy: 0.4981 - val_loss: 0.9279 - val_accuracy: 0.5365\n",
      "Epoch 7/30\n",
      "370/370 [==============================] - 24s 65ms/step - loss: 0.7777 - accuracy: 0.6305 - val_loss: 0.8616 - val_accuracy: 0.6217\n",
      "Epoch 8/30\n",
      "370/370 [==============================] - 24s 65ms/step - loss: 0.6320 - accuracy: 0.7324 - val_loss: 0.8674 - val_accuracy: 0.6460\n",
      "Epoch 9/30\n",
      "370/370 [==============================] - 24s 65ms/step - loss: 0.5212 - accuracy: 0.7897 - val_loss: 0.8463 - val_accuracy: 0.6646\n",
      "Epoch 10/30\n",
      "370/370 [==============================] - 24s 64ms/step - loss: 0.4363 - accuracy: 0.8322 - val_loss: 0.8259 - val_accuracy: 0.6871\n",
      "Epoch 11/30\n",
      "370/370 [==============================] - 24s 64ms/step - loss: 0.3687 - accuracy: 0.8639 - val_loss: 0.8799 - val_accuracy: 0.6903\n",
      "Epoch 12/30\n",
      "370/370 [==============================] - 24s 65ms/step - loss: 0.3183 - accuracy: 0.8823 - val_loss: 0.9205 - val_accuracy: 0.6924\n",
      "Epoch 13/30\n",
      "370/370 [==============================] - 24s 65ms/step - loss: 0.2834 - accuracy: 0.8968 - val_loss: 0.8799 - val_accuracy: 0.7078\n",
      "Epoch 14/30\n",
      "370/370 [==============================] - 24s 66ms/step - loss: 0.2286 - accuracy: 0.9171 - val_loss: 0.9104 - val_accuracy: 0.7187\n",
      "Epoch 15/30\n",
      "370/370 [==============================] - 24s 65ms/step - loss: 0.1989 - accuracy: 0.9284 - val_loss: 0.9649 - val_accuracy: 0.7119\n",
      "Epoch 16/30\n",
      "370/370 [==============================] - 24s 65ms/step - loss: 0.1832 - accuracy: 0.9365 - val_loss: 0.9640 - val_accuracy: 0.7199\n",
      "Epoch 17/30\n",
      "370/370 [==============================] - 24s 65ms/step - loss: 0.1712 - accuracy: 0.9420 - val_loss: 0.9865 - val_accuracy: 0.7164\n",
      "Epoch 18/30\n",
      "370/370 [==============================] - 24s 65ms/step - loss: 0.1523 - accuracy: 0.9479 - val_loss: 1.0120 - val_accuracy: 0.7238\n",
      "Epoch 19/30\n",
      "370/370 [==============================] - 24s 66ms/step - loss: 0.1457 - accuracy: 0.9495 - val_loss: 1.0260 - val_accuracy: 0.7205\n",
      "Epoch 20/30\n",
      "370/370 [==============================] - 25s 66ms/step - loss: 0.1357 - accuracy: 0.9509 - val_loss: 1.0756 - val_accuracy: 0.7202\n",
      "Epoch 21/30\n",
      "370/370 [==============================] - 24s 66ms/step - loss: 0.1292 - accuracy: 0.9525 - val_loss: 1.0891 - val_accuracy: 0.7276\n",
      "Epoch 22/30\n",
      "370/370 [==============================] - 24s 66ms/step - loss: 0.1156 - accuracy: 0.9587 - val_loss: 1.1645 - val_accuracy: 0.7196\n",
      "Epoch 23/30\n",
      "370/370 [==============================] - 24s 66ms/step - loss: 0.1016 - accuracy: 0.9656 - val_loss: 1.1708 - val_accuracy: 0.7261\n",
      "Epoch 24/30\n",
      "370/370 [==============================] - 24s 65ms/step - loss: 0.0959 - accuracy: 0.9659 - val_loss: 1.1935 - val_accuracy: 0.7232\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'custom_functions' has no attribute 'evaluate_classification_network'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 13\u001b[0m\n\u001b[0;32m      6\u001b[0m history \u001b[38;5;241m=\u001b[39m lstm_model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m      7\u001b[0m     train_ds,\n\u001b[0;32m      8\u001b[0m     epochs\u001b[38;5;241m=\u001b[39mEPOCHS,\n\u001b[0;32m      9\u001b[0m     validation_data\u001b[38;5;241m=\u001b[39mval_ds,\n\u001b[0;32m     10\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mget_callbacks(),\n\u001b[0;32m     11\u001b[0m )\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Obtain the results\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_classification_network\u001b[49m(\n\u001b[0;32m     14\u001b[0m     lstm_model, X_train\u001b[38;5;241m=\u001b[39mtrain_ds, \n\u001b[0;32m     15\u001b[0m     X_test\u001b[38;5;241m=\u001b[39mtest_ds, history\u001b[38;5;241m=\u001b[39mhistory\n\u001b[0;32m     16\u001b[0m )\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'custom_functions' has no attribute 'evaluate_classification_network'"
     ]
    }
   ],
   "source": [
    "# Build the lstm model and specify the vectorizer\n",
    "lstm_model = build_lstm_model(sequence_vectorizer)\n",
    "# Defien number of epocs\n",
    "EPOCHS = 30\n",
    "# Fit the model\n",
    "history = lstm_model.fit(\n",
    "    train_ds,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=val_ds,\n",
    "    callbacks=get_callbacks(),\n",
    ")\n",
    "# Obtain the results\n",
    "results = fn.evaluate_classification_network(\n",
    "    lstm_model, X_train=train_ds, \n",
    "    X_test=test_ds, history=history\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ef6e78-023e-4e6e-b03a-ac2e83d3a204",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_gru_model(text_vectorization_layer):\n",
    "                \n",
    "    gru_model = Sequential([\n",
    "        text_vectorization_layer,\n",
    "        tf.keras.layers.Embedding(input_dim=VOCAB_SIZE, \n",
    "                                  output_dim=EMBED_DIM, \n",
    "                                  input_length=SEQUENCE_LENGTH)])\n",
    "    # Add GRU layer *new*\n",
    "    gru_model.add(layers.GRU(128, return_sequences = True))   \n",
    "    gru_model.add(layers.GlobalMaxPooling1D())\n",
    "    # Output layer\n",
    "    gru_model.add(layers.Dense(len(classes), \n",
    "                              activation='softmax'))\n",
    "        \n",
    "    optimizer = optimizers.legacy.Adam()\n",
    "    gru_model.compile(optimizer=optimizer,  \n",
    "                  loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    gru_model.summary()\n",
    "    return gru_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f7fc673f-6db0-45e7-bd75-7ee06aa13726",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_gru_model(text_vectorization_layer):\n",
    "    VOCAB_SIZE = sequence_vectorizer.vocabulary_size()\n",
    "    SEQUENCE_LENGTH = sequence_vectorizer.get_config()['output_sequence_length']\n",
    "    EMBED_DIM = 150\n",
    "    \n",
    "    # Define sequential model with pre-trained vectorization layer and *new* embedding layer\n",
    "    gru_model = Sequential([\n",
    "        text_vectorization_layer,\n",
    "        layers.Embedding(input_dim=VOCAB_SIZE,\n",
    "                                  output_dim=EMBED_DIM, \n",
    "                                  input_length=SEQUENCE_LENGTH)\n",
    "        ])\n",
    "        \n",
    "    # Add *new* LSTM layer\n",
    "    gru_model.add(layers.GRU(128, return_sequences = True))   \n",
    "    # Add output layer\n",
    "    gru_model.add(layers.Dense(len(classes), activation='softmax'))\n",
    " \n",
    "    # Compile the model\n",
    "    gru_model.compile(optimizer=optimizers.legacy.Adam(learning_rate = .01), \n",
    "                  loss='sparse_categorical_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    gru_model.summary()\n",
    "    return lstm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3e3497ac-2fb4-4e4e-bbe7-8049043b14a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " text_vectorization (TextVec  (None, 100)              0         \n",
      " torization)                                                     \n",
      "                                                                 \n",
      " embedding_1 (Embedding)     (None, 100, 150)          3132600   \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 100, 128)          107520    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100, 3)            387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,240,507\n",
      "Trainable params: 3,240,507\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "370/370 [==============================] - 24s 64ms/step - loss: 0.0899 - accuracy: 0.9685 - val_loss: 1.1824 - val_accuracy: 0.7326\n",
      "Epoch 2/30\n",
      "370/370 [==============================] - 24s 65ms/step - loss: 0.0825 - accuracy: 0.9717 - val_loss: 1.2634 - val_accuracy: 0.7214\n",
      "Epoch 3/30\n",
      "370/370 [==============================] - 24s 65ms/step - loss: 0.0880 - accuracy: 0.9683 - val_loss: 1.2747 - val_accuracy: 0.7229\n",
      "Epoch 4/30\n",
      "370/370 [==============================] - 24s 64ms/step - loss: 0.0926 - accuracy: 0.9672 - val_loss: 1.2539 - val_accuracy: 0.7223\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'custom_functions' has no attribute 'evaluate_classification_network'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 12\u001b[0m\n\u001b[0;32m      5\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m      6\u001b[0m     train_ds,\n\u001b[0;32m      7\u001b[0m     epochs\u001b[38;5;241m=\u001b[39mEPOCHS,\n\u001b[0;32m      8\u001b[0m     validation_data\u001b[38;5;241m=\u001b[39mval_ds,\n\u001b[0;32m      9\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mget_callbacks(),\n\u001b[0;32m     10\u001b[0m )\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_classification_network\u001b[49m(\n\u001b[0;32m     13\u001b[0m     model, X_train\u001b[38;5;241m=\u001b[39mtrain_ds, \n\u001b[0;32m     14\u001b[0m     X_test\u001b[38;5;241m=\u001b[39mtest_ds, history\u001b[38;5;241m=\u001b[39mhistory)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'custom_functions' has no attribute 'evaluate_classification_network'"
     ]
    }
   ],
   "source": [
    "# Build the model\n",
    "model = build_gru_model(sequence_vectorizer)\n",
    "# Fit the model\n",
    "EPOCHS = 30\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=val_ds,\n",
    "    callbacks=get_callbacks(),\n",
    ")\n",
    "# Evaluate the model\n",
    "results = fn.evaluate_classification_network(\n",
    "    model, X_train=train_ds, \n",
    "    X_test=test_ds, history=history);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
