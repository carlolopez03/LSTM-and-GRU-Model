{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "db075fd7-28c0-4542-a736-89dd1fa67a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers, optimizers, regularizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "%load_ext autoreload \n",
    "%autoreload 2\n",
    "\n",
    "import custom_functions as fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8a62cb32-9d9b-4522-b3c7-578fe5f26fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting custom_functions\n",
      "  Obtaining dependency information for custom_functions from https://files.pythonhosted.org/packages/c9/b5/abb9a859497ddeb32ea4d09fab7d53836722e82155447d7997ac4844e7e3/custom_functions-0.3-py3-none-any.whl.metadata\n",
      "  Downloading custom_functions-0.3-py3-none-any.whl.metadata (3.4 kB)\n",
      "Downloading custom_functions-0.3-py3-none-any.whl (9.1 kB)\n",
      "Installing collected packages: custom_functions\n",
      "Successfully installed custom_functions-0.3\n"
     ]
    }
   ],
   "source": [
    "!pip install custom_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad92371c-7934-49fc-a95c-bd20b9b43556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id26305</th>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id17569</th>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id11008</th>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id27763</th>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "      <td>MWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id12958</th>\n",
       "      <td>Finding nothing else, not even gold, the Super...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text author\n",
       "id                                                               \n",
       "id26305  This process, however, afforded me no means of...    EAP\n",
       "id17569  It never once occurred to me that the fumbling...    HPL\n",
       "id11008  In his left hand was a gold snuff box, from wh...    EAP\n",
       "id27763  How lovely is spring As we looked from Windsor...    MWS\n",
       "id12958  Finding nothing else, not even gold, the Super...    HPL"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading Data\n",
    "df = pd.read_csv(\"Data/spooky.csv\", index_col = 'id')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9498dff-7eac-4449-a28b-75f56a680a20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id26305</th>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id17569</th>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id11008</th>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id27763</th>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "      <td>MWS</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id12958</th>\n",
       "      <td>Finding nothing else, not even gold, the Super...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text author  length\n",
       "id                                                                       \n",
       "id26305  This process, however, afforded me no means of...    EAP      41\n",
       "id17569  It never once occurred to me that the fumbling...    HPL      14\n",
       "id11008  In his left hand was a gold snuff box, from wh...    EAP      36\n",
       "id27763  How lovely is spring As we looked from Windsor...    MWS      34\n",
       "id12958  Finding nothing else, not even gold, the Super...    HPL      27"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Making length column for text\n",
    "df['length'] =df['text'].map( lambda x: len(x.split(\" \")))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c428f3ae-58c0-44dd-aefe-e40020c77bde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    19579.000000\n",
       "mean        26.730477\n",
       "std         19.048353\n",
       "min          2.000000\n",
       "25%         15.000000\n",
       "50%         23.000000\n",
       "75%         34.000000\n",
       "max        861.000000\n",
       "Name: length, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['length'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46834f51-20d4-4431-a858-011f79ca2211",
   "metadata": {},
   "source": [
    "- The range of sequence length is from 2 to 861.\n",
    "- The average sequence length is around 26 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "843644ae-6429-45f0-b5d1-74599be85309",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EAP    0.403494\n",
       "MWS    0.308698\n",
       "HPL    0.287808\n",
       "Name: author, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['author'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "349e4fc4-bae3-4c13-9bd7-3f8b3ff1c126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EAP    5635\n",
       "HPL    5635\n",
       "MWS    5635\n",
       "Name: author, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RUS to match minority group\n",
    "sampler = RandomUnderSampler(random_state=42)\n",
    "df,  _ = sampler.fit_resample(df, df['author'])\n",
    "df['author'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d97f370b-9084-4621-a49e-cd5a12ee695a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "id22483    0\n",
       "id18809    0\n",
       "id16322    0\n",
       "id13423    0\n",
       "id09553    0\n",
       "          ..\n",
       "id24420    2\n",
       "id24838    2\n",
       "id16500    2\n",
       "id23728    2\n",
       "id04963    2\n",
       "Name: author, Length: 16905, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Crating map for targets\n",
    "target_map = {'EAP':0,\n",
    "             'HPL':1,\n",
    "             'MWS':2}\n",
    "y = df['author'].map(target_map)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c6bdd5e-c81a-4ed6-8760-f23f3791cd9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['He then asked me, suddenly, if I had observed any thing peculiar at the scene of the atrocity.',\n",
       "       'Through the exertions of Beauvais, the matter was industriously hushed up, as far as possible; and several days had elapsed before any public emotion resulted.',\n",
       "       'The cold was intense, and obliged me to wrap up closely in an overcoat.',\n",
       "       ...,\n",
       "       'But my heart sank within me as with bitter sickness, and I refrained.',\n",
       "       \"Perdita's name was for ever joined with his; their conjugal felicity was celebrated even by the authentic testimony of facts.\",\n",
       "       'I shall not be suspected of being averse to the Greek cause; I know and feel its necessity; it is beyond every other a good cause.'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X and y\n",
    "X = df['text'].values\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "39bc53c3-1654-4686-8166-f132972a6394",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = y.unique()\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ab6456e-7cb7-4252-b3ec-b960ee44b652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to Dataset Object\n",
    "ds = tf.data.Dataset.from_tensor_slices((X, y))\n",
    "\n",
    "# Shuffle dataset\n",
    "ds = ds.shuffle(buffer_size=len(ds),reshuffle_each_iteration=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ca0469c-5dba-4758-b509-5c491f844bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    - train:\t11833 samples \t(370 batches)\n",
      "    - val:  \t3381 samples \t(106 batches)\n",
      "    - test: \t1691 samples \t(53 batches)\n"
     ]
    }
   ],
   "source": [
    "# Set the ratio of the train, validation, test split\n",
    "split_train = .7\n",
    "split_val =  .2\n",
    "split_test =  1 -( split_train + split_val )\n",
    "\n",
    "# Calculate the number of samples for training and validation data \n",
    "n_train_samples =  int(len(ds) * split_train)\n",
    "n_val_samples = int(len(ds) * split_val)\n",
    "n_test_samples = len(ds) -(n_train_samples + n_val_samples)\n",
    "\n",
    "# Set the batch size\n",
    "BATCH_SIZE =32\n",
    "\n",
    "\n",
    "import math\n",
    "# math.ceil will round up\n",
    "# How many batches? \n",
    "n_train_batches = math.ceil(n_train_samples/BATCH_SIZE)\n",
    "n_val_batches = math.ceil(n_val_samples/BATCH_SIZE)\n",
    "n_test_batches = math.ceil(n_test_samples/BATCH_SIZE)\n",
    "\n",
    "print(f\"    - train:\\t{n_train_samples} samples \\t({n_train_batches} batches)\")\n",
    "print(f\"    - val:  \\t{n_val_samples} samples \\t({n_val_batches} batches)\")\n",
    "print(f\"    - test: \\t{n_test_samples} samples \\t({n_test_batches} batches)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4624175-d676-4fbb-be77-40c8d759175f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use take and skip to define each set\n",
    "train_ds = ds.take(n_train_samples).batch(batch_size=BATCH_SIZE)\n",
    "\n",
    "# Skip over the training batches and take the validation batches\n",
    "val_ds = ds.skip(n_train_samples).take(n_val_samples).batch(batch_size=BATCH_SIZE)\n",
    "\n",
    "# Skipver the train and validation batches, the remaining are the test batches\n",
    "test_ds = ds.skip(n_train_samples + n_val_samples).batch(batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d56d8ce-a8ff-429b-8b70-39e7608c5e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " There are 370 training batches.\n",
      " There are 106 validation batches.\n",
      " There are 53 testing batches.\n"
     ]
    }
   ],
   "source": [
    "# Confirm the number of batches in each\n",
    "print (f' There are {len(train_ds)} training batches.')\n",
    "print (f' There are {len(val_ds)} validation batches.')\n",
    "print (f' There are {len(test_ds)} testing batches.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8482f787-27db-40b9-87e9-2e193588241b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQUENCE_LENGTH = 100\n",
    "# Create text Vectorization layer\n",
    "sequence_vectorizer = tf.keras.layers.TextVectorization(standardize=\"lower_and_strip_punctuation\",\n",
    "                                                        output_mode=\"int\",\n",
    "                                                        output_sequence_length=SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b83d6b6-0ac2-4341-91b0-0ee07f360de9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32,), dtype=string, numpy=\n",
       "array([b'The first ranks had muskets; some were mounted, but their arms were such as they had seized during their advance, their horses those they had taken from the peasantry; there was no uniformity, and little obedience, but their shouts and wild gestures showed the untamed spirit that inspired them.',\n",
       "       b'Dupin seemed singularly interested in the progress of this affair at least so I judged from his manner, for he made no comments.',\n",
       "       b'The main building was about twenty four feet long and sixteen broad certainly not more.',\n",
       "       b'Here, the address, to the Minister, diminutive and feminine; there the superscription, to a certain royal personage, was markedly bold and decided; the size alone formed a point of correspondence.',\n",
       "       b\"But the beauty and regularity of the new town of Edinburgh, its romantic castle and its environs, the most delightful in the world, Arthur's Seat, St. Bernard's Well, and the Pentland Hills compensated him for the change and filled him with cheerfulness and admiration.\",\n",
       "       b\"The real diameter of the same comet's nebulosity is observed to contract rapidly as it approaches the sun, and dilate with equal rapidity in its departure towards its aphelion.\",\n",
       "       b'Light indeed glowed on the panels ahead, but it was not any light that the moon gives.',\n",
       "       b'The sight of it soothed her.',\n",
       "       b'There had been servants Ann White especially who would not use the cellar kitchen, and at least three well defined legends bore upon the queer quasi human or diabolic outlines assumed by tree roots and patches of mould in that region.',\n",
       "       b'\"But there are still other and stronger reasons for believing them so deposited, than any which I have as yet urged.',\n",
       "       b'It had been locked, and I did not find the key till it occurred to me to examine the personal ring which the professor carried always in his pocket.',\n",
       "       b'The buds decked the trees, the flowers adorned the land: the dark branches, swollen with seasonable juices, expanded into leaves, and the variegated foliage of spring, bending and singing in the breeze, rejoiced in the genial warmth of the unclouded empyrean: the brooks flowed murmuring, the sea was waveless, and the promontories that over hung it were reflected in the placid waters; birds awoke in the woods, while abundant food for man and beast sprung up from the dark ground.',\n",
       "       b'I gave to each heroine of whom I read, her beauty and matchless excellences such was Antigone, when she guided the blind Oedipus to the grove of the Eumenides, and discharged the funeral rites of Polynices; such was Miranda in the unvisited cave of Prospero; such Haidee, on the sands of the Ionian island.',\n",
       "       b'I strained my vision to detect any motion in the corpse but there was not the slightest perceptible.',\n",
       "       b'What had she done the while, how supported his absence and neglect?',\n",
       "       b\"M. Verhaeren, Belgian agent at a trading post on the Congo, believed that he could not only locate but obtain the stuffed goddess, of which he had vaguely heard; since the once mighty N'bangus were now the submissive servants of King Albert's government, and with but little persuasion could be induced to part with the gruesome deity they had carried off.\",\n",
       "       b'The \"Gad Fly\" was, of course, brought upon the tapis, and I hope never to be subjected to a criticism so searching, or to rebukes so withering, as were bestowed by Mr. Crab upon that unhappy effusion.',\n",
       "       b'But I did not believe my errors to be irretrievable, and after much consideration I resolved to return to the cottage, seek the old man, and by my representations win him to my party.',\n",
       "       b'Even now if we had courage we might be free.',\n",
       "       b'This circumstance favored me greatly in the project I now determined to adopt.',\n",
       "       b'Great honours were then paid to the shades of those who had annihilated the odd ancient beings, and the memory of those beings and of their elder gods was derided by dancers and lutanists crowned with roses from the gardens of Zokkar.',\n",
       "       b'Let us, for example, imagine the Automaton to play with his right arm.',\n",
       "       b'My life was spent among tangible realities, hers was a dream.',\n",
       "       b'Tears also gushed from the eyes of Clerval, as he read the account of my misfortune.',\n",
       "       b'At that time a party made investigations, finding the house deserted and partly in ruins.',\n",
       "       b'In , when a scholarly correspondent from Miskatonic University called upon him one day and departed pale and puzzled, he was fully six and three quarters feet tall.',\n",
       "       b'I repeat that the principle here expressed, is incontrovertible; but there may be something even beyond it.',\n",
       "       b'\"No\" said the Baron, turning abruptly toward the speaker, \"dead say you?\" \"It is indeed true, my lord; and, to a noble of your name, will be, I imagine, no unwelcome intelligence.\"',\n",
       "       b'\"Having thus before us the whole philosophy of this subject, we can easily test by it the assertions of L\\'Etoile.',\n",
       "       b'Elizabeth read my anguish in my countenance, and kindly taking my hand, said, \"My dearest friend, you must calm yourself.',\n",
       "       b'The atrocity of this murder, for it was at once evident that murder had been committed, the youth and beauty of the victim, and, above all, her previous notoriety, conspired to produce intense excitement in the minds of the sensitive Parisians.',\n",
       "       b'I reflected that many difficulties might still lie in the path of my preservation which only extreme exertion on my part would be able to surmount.'],\n",
       "      dtype=object)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get just the text from ds_train\n",
    "ds_texts = train_ds.map(lambda x, y: x)\n",
    "\n",
    "# Preview the text\n",
    "ds_texts.take(1).get_single_element()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c7f66bb4-affc-473b-ba92-e5e451fda909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20939"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train (adapt on training text data))\n",
    "sequence_vectorizer.adapt(ds_texts)\n",
    "sequence_vectorizer.vocabulary_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "626a564d-9759-4300-96a1-367121ffe607",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm_model(text_vectorization_layer):\n",
    "    VOCAB_SIZE = sequence_vectorizer.vocabulary_size()\n",
    "    SEQUENCE_LENGTH = sequence_vectorizer.get_config()['output_sequence_length']\n",
    "    EMBED_DIM = 150\n",
    "    \n",
    "    # Define sequential model with pre-trained vectorization layer and *new* embedding layer\n",
    "    lstm_model = Sequential([\n",
    "        text_vectorization_layer,\n",
    "        layers.Embedding(input_dim=VOCAB_SIZE,\n",
    "                                  output_dim=EMBED_DIM, \n",
    "                                  input_length=SEQUENCE_LENGTH)\n",
    "        ])\n",
    "        \n",
    "    # Add *new* LSTM layer\n",
    "    lstm_model.add(layers.LSTM(128))\n",
    "    # Add output layer\n",
    "    lstm_model.add(layers.Dense(len(classes), activation='softmax'))\n",
    " \n",
    "    # Compile the model\n",
    "    lstm_model.compile(optimizer=optimizers.legacy.Adam(learning_rate = .01), \n",
    "                  loss='sparse_categorical_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    lstm_model.summary()\n",
    "    return lstm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aab69523-041e-413d-9855-297bee0ca614",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_callbacks(patience=3, monitor='val_accuracy'):\n",
    "    early_stop = tf.keras.callbacks.EarlyStopping(patience=patience, monitor=monitor)\n",
    "    return [early_stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d53ad177-e2a8-42c7-a9c3-b067bdcac12c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " text_vectorization (TextVec  (None, 100)              0         \n",
      " torization)                                                     \n",
      "                                                                 \n",
      " embedding_2 (Embedding)     (None, 100, 150)          3140850   \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 128)               142848    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,284,085\n",
      "Trainable params: 3,284,085\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "370/370 [==============================] - 24s 63ms/step - loss: 1.1006 - accuracy: 0.3342 - val_loss: 1.0992 - val_accuracy: 0.3425\n",
      "Epoch 2/30\n",
      "370/370 [==============================] - 23s 62ms/step - loss: 1.1000 - accuracy: 0.3299 - val_loss: 1.1026 - val_accuracy: 0.3431\n",
      "Epoch 3/30\n",
      "370/370 [==============================] - 23s 63ms/step - loss: 1.0984 - accuracy: 0.3337 - val_loss: 1.1064 - val_accuracy: 0.3422\n",
      "Epoch 4/30\n",
      "370/370 [==============================] - 23s 63ms/step - loss: 1.0958 - accuracy: 0.3349 - val_loss: 1.1102 - val_accuracy: 0.3419\n",
      "Epoch 5/30\n",
      "370/370 [==============================] - 24s 64ms/step - loss: 1.0954 - accuracy: 0.3348 - val_loss: 1.1130 - val_accuracy: 0.3413\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'custom_functions' has no attribute 'evaluate_classification_network'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 13\u001b[0m\n\u001b[0;32m      6\u001b[0m history \u001b[38;5;241m=\u001b[39m lstm_model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m      7\u001b[0m     train_ds,\n\u001b[0;32m      8\u001b[0m     epochs\u001b[38;5;241m=\u001b[39mEPOCHS,\n\u001b[0;32m      9\u001b[0m     validation_data\u001b[38;5;241m=\u001b[39mval_ds,\n\u001b[0;32m     10\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mget_callbacks(),\n\u001b[0;32m     11\u001b[0m )\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Obtain the results\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_classification_network\u001b[49m(\n\u001b[0;32m     14\u001b[0m     lstm_model, X_train\u001b[38;5;241m=\u001b[39mtrain_ds, \n\u001b[0;32m     15\u001b[0m     X_test\u001b[38;5;241m=\u001b[39mtest_ds, history\u001b[38;5;241m=\u001b[39mhistory\n\u001b[0;32m     16\u001b[0m )\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'custom_functions' has no attribute 'evaluate_classification_network'"
     ]
    }
   ],
   "source": [
    "# Build the lstm model and specify the vectorizer\n",
    "lstm_model = build_lstm_model(sequence_vectorizer)\n",
    "# Defien number of epocs\n",
    "EPOCHS = 30\n",
    "# Fit the model\n",
    "history = lstm_model.fit(\n",
    "    train_ds,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=val_ds,\n",
    "    callbacks=get_callbacks(),\n",
    ")\n",
    "# Obtain the results\n",
    "results = fn.evaluate_classification_network(\n",
    "    lstm_model, X_train=train_ds, \n",
    "    X_test=test_ds, history=history\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ef6e78-023e-4e6e-b03a-ac2e83d3a204",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
